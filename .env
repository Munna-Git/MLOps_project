# Paths
RAW_DATA_FILEPATH=D:/mlops_project/data/raw/Customer-Churn-Records.csv
CLEANED_DATA_FILEPATH=D:/mlops_project/data/cleaned/CustomerChurnCleaned.csv
PROCESSED_DATA_DIR=D:/mlops_project/data/processed
MODEL_OUTPUT_DIR=D:/mlops_project/models
MODEL_FILENAME=xgboost_model.pkl
TEST_DATA_PATH=D:/mlops_project/data/raw/InferenceData.csv
INFERENCE_CLEANED_PATH=D:/mlops_project/data/cleaned/InferenceCleaned.csv

# Model
MODEL_PATH=D:/mlops_project/models/xgboost_model.pkl

# Training Parameters
TEST_SIZE=0.1

# ========== NEW: MLflow Configuration ==========

# MLflow Tracking (where experiments are logged)
# Default: file:./mlruns (local directory)
# Remote example: http://localhost:5000 (if running MLflow server)
MLFLOW_TRACKING_URI=file:./mlruns

# MLflow Experiment Name
MLFLOW_EXPERIMENT_NAME=customer-churn-prediction

# MLflow Artifact Storage Root
MLFLOW_ARTIFACT_ROOT=./mlruns

# ========== NEW: MLflow Model Loading for Inference ==========

# Set to true to load model from MLflow Registry instead of pickle file
USE_MLFLOW_MODEL=false

# MLflow Model Registry Settings (only used if USE_MLFLOW_MODEL=true)
MLFLOW_MODEL_NAME=customer-churn-xgboost
MLFLOW_MODEL_STAGE=Production  # Options: Production, Staging, Archived, None

# Note: To use MLflow models in inference:
# 1. Train model with train_entrypoint.py (auto-registers model)
# 2. Transition model to Production stage in MLflow UI
# 3. Set USE_MLFLOW_MODEL=true above
# 4. Run inference_entrypoint.py