{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc2dabab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle  # For saving the scaler object\n",
    "import os\n",
    "\n",
    "# sklearn for train-test split, scaling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "\n",
    "# imbalanced data handling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b41d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options to display all columns and rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.display.float_format = '{:,.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3a62a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/cleaned/CustomerChurnCleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abbf775b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Satisfaction Score</th>\n",
       "      <th>CardType</th>\n",
       "      <th>PointEarned</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101,348.880</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>464</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83,807.860</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112,542.580</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>456</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159,660.800</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113,931.570</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>377</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93,826.630</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>350</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125,510.820</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79,084.100</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>425</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure     Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.000              1          1   \n",
       "1          608   41       1  83,807.860              1          0   \n",
       "2          502   42       8 159,660.800              3          1   \n",
       "3          699   39       1       0.000              2          0   \n",
       "4          850   43       2 125,510.820              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Satisfaction Score  CardType  \\\n",
       "0               1      101,348.880       1                   2         3   \n",
       "1               1      112,542.580       0                   3         3   \n",
       "2               0      113,931.570       1                   3         3   \n",
       "3               0       93,826.630       0                   5         1   \n",
       "4               1       79,084.100       0                   5         1   \n",
       "\n",
       "   PointEarned  Geography_France  Geography_Germany  Geography_Spain  \\\n",
       "0          464              True              False            False   \n",
       "1          456             False              False             True   \n",
       "2          377              True              False            False   \n",
       "3          350              True              False            False   \n",
       "4          425             False              False             True   \n",
       "\n",
       "   Gender_Female  Gender_Male  \n",
       "0           True        False  \n",
       "1           True        False  \n",
       "2           True        False  \n",
       "3           True        False  \n",
       "4           True        False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c19c2c3",
   "metadata": {},
   "source": [
    "### 1. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10b96a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df: pd.DataFrame, target: str, test_size: float = 0.1, val_size: float = 0.1, random_state: int = 42) -> tuple:\n",
    "    \"\"\"\n",
    "    Splits the dataset into training, validation, and testing sets with stratification on the target variable.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input dataframe.\n",
    "    - target (str): The name of the target column.\n",
    "    - test_size (float): The proportion of the data to include in the test split.\n",
    "    - val_size (float): The proportion of the train data to include in the validation set.\n",
    "    - random_state (int): Controls the shuffling applied to the data before applying the split.\n",
    "\n",
    "    Returns:\n",
    "    - X_train, X_val, X_test, y_train, y_val, y_test: The training, validation, and test sets for features and target.\n",
    "    \"\"\"\n",
    "    # First split: train + validation and test set\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Second split: split train into train and validation\n",
    "    # X_train, X_val, y_train, y_val = train_test_split(\n",
    "    #     X_train, y_train, test_size=val_size / (1 - test_size), stratify=y_train, random_state=random_state\n",
    "    # )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test #, X_val ,y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3dcf1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(df, \"Exited\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885cf0f2",
   "metadata": {},
   "source": [
    "### 2. Scaling Numeric Feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a0fce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features to scale (excluding ID and any encoded variables)\n",
    "features_to_scale = [\n",
    "    'Customer_Age',\n",
    "    'Dependent_Count',\n",
    "    'Months_on_book',\n",
    "    'Total_Relationship_Count',\n",
    "    'Months_Inactive_12_mon',\n",
    "    'Contacts_Count_12_mon',\n",
    "    'Credit_Limit',\n",
    "    'Total_Revolving_Bal',\n",
    "    'Total_Amt_Chng_Q4_Q1',\n",
    "    'Total_Trans_Amt',\n",
    "    'Total_Trans_Ct',\n",
    "    'Total_Ct_Chng_Q4_Q1',\n",
    "    'Avg_Utilization_Ratio'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae0287ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X_train: pd.DataFrame, X_val: pd.DataFrame, X_test: pd.DataFrame, features_to_scale: list) -> tuple:\n",
    "    \"\"\"\n",
    "    Scales the specified features in the training, validation, and testing data using MinMaxScaler.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train (pd.DataFrame): The training data features.\n",
    "    - X_val (pd.DataFrame): The validation data features.\n",
    "    - X_test (pd.DataFrame): The testing data features.\n",
    "    - features_to_scale (list): List of features to scale.\n",
    "\n",
    "    Returns:\n",
    "    - X_train_scaled, X_val_scaled, X_test_scaled, scaler: The scaled data, and the scaler object.\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Create copies to avoid modifying the original DataFrames\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_val_scaled = X_val.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "\n",
    "    # Fit and transform the training data, and transform validation and test data\n",
    "    X_train_scaled[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
    "    X_val_scaled[features_to_scale] = scaler.transform(X_val[features_to_scale])\n",
    "    X_test_scaled[features_to_scale] = scaler.transform(X_test[features_to_scale])\n",
    "\n",
    "    return X_train_scaled, X_val_scaled, X_test_scaled, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "268d3579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_scaled, X_val_scaled, X_test_scaled, scaler = scale_data(X_train, X_val, X_test, features_to_scale)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8d368c",
   "metadata": {},
   "source": [
    "### 3. Saving the Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80259942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_scaler(scaler, filename: str):\n",
    "    \"\"\"\n",
    "    Saves the scaler object as a pickle file for later use.\n",
    "\n",
    "    Parameters:\n",
    "    - scaler: The scaler object to save.\n",
    "    - filename (str): The name of the pickle file.\n",
    "    \"\"\"\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9162bd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save_scaler(scaler, \"../models/scaler_minmax.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0416acf0",
   "metadata": {},
   "source": [
    "### 4. Handling Data Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09816949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_imbalance(X_train: pd.DataFrame, y_train: pd.Series) -> tuple:\n",
    "    \"\"\"\n",
    "    Balances the training data using the specified method (e.g., SMOTE).\n",
    "\n",
    "    Parameters:\n",
    "    - X_train (pd.DataFrame): The training data features.\n",
    "    - y_train (pd.Series): The training data target.\n",
    "\n",
    "    Returns:\n",
    "    - X_res, y_res: The resampled training data.\n",
    "    \"\"\"\n",
    "    resampler = SMOTE(random_state=42)\n",
    "    \n",
    "    X_res, y_res = resampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    return X_res, y_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f3e6c8",
   "metadata": {},
   "source": [
    "### 5. Save Scaled Data to Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fd17c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(X: pd.DataFrame, y: pd.Series, data_type: str, stage: str, base_directory: str = '../data'):\n",
    "    \"\"\"\n",
    "    Saves features and target variables to the specified stage in both CSV and Pickle format.\n",
    "\n",
    "    Parameters:\n",
    "    - X (pd.DataFrame): Features to save.\n",
    "    - y (pd.Series): Target variable to save.\n",
    "    - data_type (str): The type of data (e.g., 'train', 'val', 'test').\n",
    "    - stage (str): The processing stage (e.g., 'transformed', 'processed').\n",
    "    - base_directory (str): Base directory for saving data.\n",
    "    \"\"\"\n",
    "    directory = os.path.join(base_directory, stage)\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Save as Pickle\n",
    "    with open(f'{directory}/X_{data_type}.pkl', 'wb') as f:\n",
    "        pickle.dump(X, f)\n",
    "    \n",
    "    with open(f'{directory}/y_{data_type}.pkl', 'wb') as f:\n",
    "        pickle.dump(y, f)\n",
    "\n",
    "    #Save as CSV\n",
    "    X.to_csv(f'{directory}/X_{data_type}.csv', index=False)\n",
    "    y.to_csv(f'{directory}/y_{data_type}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfa0458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(X_train, y_train, 'train', 'processed')\n",
    "save_data(X_test, y_test, 'test', 'processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2383da",
   "metadata": {},
   "source": [
    "Why save as Pickle (pkl)?\n",
    "\n",
    "Pickle preserves Python objects exactly as they are.\n",
    "\n",
    "- DataFrame with dtypes, categories, index names, etc.\n",
    "\n",
    "- Series/DataFrame metadata that CSV might lose.\n",
    "\n",
    "Much faster to save and load than CSV (especially for large datasets).\n",
    "\n",
    "Avoids potential issues like CSV mis-parsing, delimiter problems, or dtype conversion (e.g., float64 becoming object).\n",
    "\n",
    "Handy for intermediate pipeline stages where you want to quickly reload and continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4b707b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
